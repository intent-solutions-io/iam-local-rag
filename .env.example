# NEXUS Configuration
# Copy this file to .env and customize for your environment

# --- Mode Selection ---
# local: Ollama only (no cloud) | cloud: Cloud LLMs only | hybrid: Local retrieval + cloud generation
NEXUS_MODE=hybrid

# --- LLM Provider ---
# ollama | anthropic | openai | vertex
NEXUS_LLM_PROVIDER=ollama

# --- Embedding Provider ---
# ollama | openai | vertex
NEXUS_EMBED_PROVIDER=ollama

# --- Ollama Configuration ---
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434

# --- Anthropic Configuration (optional, for cloud/hybrid mode) ---
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=

# --- OpenAI Configuration (optional, for cloud/hybrid mode) ---
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=
OPENAI_MODEL=gpt-4-turbo-preview

# --- Google Vertex AI Configuration (optional, for cloud/hybrid mode) ---
GOOGLE_CLOUD_PROJECT=
GOOGLE_CLOUD_REGION=us-central1
VERTEX_MODEL=gemini-1.5-pro

# --- Document Processing ---
DOCUMENTS_DIR=documents
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# --- Vector Store ---
CHROMA_DB_PATH=./chroma_db_optimized
CACHE_DIR=./rag_cache

# --- Performance Tuning ---
EMBEDDING_BATCH_SIZE=50
MAX_WORKERS=4
CACHE_TTL=3600
MAX_CACHE_SIZE=100

# --- API Configuration (Phase 3) ---
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# --- Privacy/Security Settings ---
# When true, only send retrieved snippets to cloud (not full documents)
HYBRID_SAFE_MODE=true
# Maximum characters to send to cloud LLM
MAX_SNIPPET_LENGTH=4000
